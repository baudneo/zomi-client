# Same as ZM ML, allows for ${} wrapped BASH like variables to be substituted
substitutions:
  CFG_DIR: /etc/zm
  MODEL_DIR: /shared/models
  # This file contains substitutions that will be imported into this file (secrets)
  # NOTE: The 'IncludeFile' directive must be contained in the 'substitutions' section
#  IncludeFile: /etc/zm/secrets.yml

# Directory of ZoneMinder zm.conf file and conf.d dir
zm_conf: "${CFG_DIR}"

# log status updates
status_updates:
  enabled: yes
  # status update every x frames
  every: 50

logging:
  debug: yes
  # log to a file and console
  file:
    enabled: yes
    # zm log directory
    path: /var/log/zm
    #
    filename: annotate_events.log  # If the event is from monitor 4 this becomes annotated_m4.log

# Until filters and per monitor overrides work, only annotate these labels
annotate_labels:
  - person
  - car
  - truck
  - bus
  - dog
  - cat
  - bicycle
  - motorbike

output:
  # resize the output video to this siz#
  resize:
    enabled: no
    width:
    height:
    # Try to keep the aspect ratio
    keep_aspect: yes

# If the event is a JPG stored event, The DB is queried for the encoding FPS
db:
  # Leave empty to try and read values from zm .conf files (requires zm_conf to be set!)
  host:
  port:
  user:
  password:
  name:

# Skip x frames between running ML. use this for low powered CPU only systems
# Default is 1 (run ML on every frame)
frame_skip: 1

# If local and remote are enabled, remote will be used
local:
  # Run ML locally.
  enabled: yes

  model:
    name: yolov4
    confidence: 0.3
    nms: 0.323
    # height and width of images for the model
    width: 416
    height: 416
    input: ${MODEL_DIR}/yolo/yolov4_new.weights  # REQUIRED
    config: ${MODEL_DIR}/yolo/yolov4_new.cfg
    # If labels is unspecified, COCO17 labels will be used by default
#    labels: /opt/zm_ml/data/models/yolov4/coco.names


# Send to MLAPI instead of processing locally
remote:
  enabled: yes
  host: 10.0.1.7
  port: 5000
  username: zmml
  password: mlzm
  # what models to request for each frame sent to MLAPI
  models:
    - yolov4

# This is all WIP aka NOT WORKING YET
label_groups:
  # These are 'groups' of labels that can be used for per monitor filtering
  animals:
    - dog
    - cat
    - bird
    - horse
    - mouse
  vehicles:
    - car
    - truck
    - bus
    - motorbike
    - boat
  # For face detection/recognition
  friends:
    - Bart
    - Maggie
    - Lisa
  foes:
    - Nelson
    - Sideshow Bob
    - Mr. Burns

# Import zones defined in ZM
import_zones: yes


filters:
  # This is globally applied to all monitors but can be overridden on a per monitor basis
  object:
    min_conf: 0.42069
    pattern: "(DEFAULT PATTERN|car|truck|bus|person|dog|cat)"
    total_max_area: 100%
    total_min_area: 1px
  face:
    pattern: ".*"
  alpr:
    pattern: ".*"
    min_conf: 0.456

monitors:
  # Override settings based on which monitor an event was triggered by

  09842773845637546357216:
    name: Front
    # -- Cooldown between notifications config
    cooldown:
      enabled: yes
      seconds: 60
      # -- 'Link' monitors into a group. 'linked:' is only available in the Monitor section.
      # -- If any monitor in the group is within the cooldown period, nothing is sent.
      # -- If you have multiple cameras covering the same area, you can link them together.
#      linked:
#        - 1
#        - 2

    # -- Monitor level - static objects
    static_objects:
      enabled: no
      # -- difference in area between current and previous detection
      difference: 18%
      # only check if these labels are static (label_groups supported)
      labels:
        - car

    # Monitor level filters (these override global filters and can be overridden by zone level filters)
    filters:
      object:
        min_conf: .498
        pattern: "(MONITOR LEVEL PATTERN|person|dog|cat)"
    zones:
      # -- These are zones that are defined in the config file on top of imported ZoneMinder zones
      # -- If you import ZM zones you can add a ML config for that zone here.
      # -- Example: If the imported zone is named "Yard", this would set the ML config for it.
      Yard:
        enabled: yes
        # zone level filters (these override global and monitor level filters)
        filters:
          static_objects:
            enabled: no
          object:
            # min_conf for the zone
            min_conf: .499
            pattern: "(person|dog|cat)"
            # -- Per label filtering (label_groups supported)
            # -- Trained faces are labeled with the name of the person it was trained for
            labels:
              # filters for 'person' label
              person:
                # min_conf for 'person' label in this zone
                min_conf: 0.5
                # -- The minimum and maximum area of the detection box in pixels or percentage of the zone.
                # -- (how much of the zone is covered by the detection box)
#                min_area: 10px
#                max_area: 10%
                # -- The minimum and maximum area of the detection box in pixels or percentage of the full image.
                # -- (how much of the image is covered by the detection box)
#                total_min_area: 10px
#                total_max_area: 10%
          face:
            # -- You can specify trained face names here, only pattern supported currently
            pattern: ".*"
            # pattern: "(James|Addison)"
          alpr:
            # -- Only pattern and min_conf supported
            pattern: ".*"
            min_conf: 0.1